{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(echo = TRUE)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introduction\n",
                "\n",
                "In this EDA, I explore a dataset of airline on-time performance to try and find insights to flight delay and cancellations. The dataset used is a very large dataset that consists of flight arrival and departure details for all commercial flights within the USA, from October 1987 to April 2008. There are over 120 million observations (flights) in this dataset for flights. The data was compressed into individual CSV files for each year.\n",
                "\n",
                "I chose to explore this particular dataset because it would allow me learn new skills and optimization techniques for handling large datasets.\n",
                "\n",
                "Due to the size of this dataset, it would very difficult to load the data into a Pandas dataframe in memory without reducing it to a very small subset of the data, so I decided to employ the use of R markdown (instead of Jupyter notebook) so that I can use R packages, along with SQL queries, to wrangle the data into a more summarized format that a Pandas dataframe can handle.\n",
                "\n",
                "## Preliminary Wrangling\n",
                "\n",
                "### Importing R Libraries\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(tidyverse)\n",
                "library(skimr)\n",
                "library(dplyr)\n",
                "library(here) # To locate files based on current working directory\n",
                "library(janitor) # Tools for for examining and cleaning dirty data.\n",
                "library(reticulate) # For reading R objects in Python\n",
                "library(data.table) # For reading large datasets efficiently\n",
                "library(inborutils) # For reading CSV files and converting to SQL\n",
                "library(DBI) # Interface to connect with SQL databases\n",
                "library(RSQLite) # For connecting with SQL databases\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Importing Python Packages\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from pandas.api.types import CategoricalDtype\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import pathlib\n",
                "import os\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Loading In The Data\n",
                "\n",
                "This dataset contains 21 large CSV files of flight data for each year from 1987 to 2008, as well as some other CSV files for which contain extra information. I will not directly read any of the large CSV files because it would take too much memory. I will read in the other CSV files, then use R libraries and SQL queries to read in smaller samples of the data to explore.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path_column_data = \"airline/airline_dataset_column_info.csv\"\n",
                "path_airport_data = \"airline/other_data/airports.csv\"\n",
                "path_carrier_data = \"airline/other_data/carriers.csv\"\n",
                "path_plane_data = \"airline/other_data/plane-data.csv\"\n",
                "path_main = \"airline/main_data\" # Path to the main (yearly) CSV files\n",
                "\n",
                "def absolute_file_paths(directory):\n",
                "    data = {}\n",
                "    files = os.listdir(directory)\n",
                "    paths = [f\"{path_main}/{file}\" for file in files]\n",
                "    \n",
                "    for idx in range(len(files)):\n",
                "        name = files[idx].split('.')[0]\n",
                "        data[name] = paths[idx]\n",
                "    return data\n",
                "\n",
                "main_files = absolute_file_paths(path_main)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data on column descriptions for the main files\n",
                "column_data = pd.read_csv(path_column_data)\n",
                "\n",
                "# Data on different airports\n",
                "airport_data = pd.read_csv(path_airport_data)\n",
                "\n",
                "# Airline companies\n",
                "carrier_data = pd.read_csv(path_carrier_data)\n",
                "\n",
                "# Plane data, specifications and other info\n",
                "plane_data = pd.read_csv(path_plane_data)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Info on column descriptions for the main files\n",
                "column_data <- read.csv(py$path_column_data)\n",
                "\n",
                "# Data on different airports\n",
                "airport_data <- read.csv(py$path_airport_data)\n",
                "\n",
                "# Information on airline companies\n",
                "carrier_data <- read.csv(py$path_carrier_data)\n",
                "\n",
                "# Plane data, specifications and other info\n",
                "plane_data <- read.csv(py$path_plane_data)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For the main data, I have written a script that reads in the data in smaller chunks and stores them in a database file (sqlite). Each year's data is stored in its own table. I also store the other data in their own tables so that later, when needed, I can reference them using SQL joins. The process takes a while to run because of the large dataset (over 30 minutes on my PC).\n",
                "\n",
                "Also, the original files are named by the year they represent. It is not be good practice to name a database table starting with a number, so the script adds a prefix to each name.\n",
                "\n",
                "For now, I have added a condition so the code will only be executed if the sqlite file is not detected in the project root directory.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path_main <- \"airline/main_data\"\n",
                "db_file <- \"airline_data.sqlite\"\n",
                "\n",
                "save_in_sql <- function() {\n",
                "  main_files <- list.files(path = path_main, full.names = TRUE)\n",
                "  \n",
                "  if (!file.exists(db_file)) {\n",
                "    # Creating the airport data table\n",
                "    inborutils::csv_to_sqlite(\n",
                "                csv_file = py$path_airport_data,\n",
                "                table_name = \"airports\",\n",
                "                sqlite_file = db_file,\n",
                "                show_progress_bar = FALSE)\n",
                "    \n",
                "    # Creating the carrier data table\n",
                "    inborutils::csv_to_sqlite(\n",
                "                csv_file = py$path_carrier_data,\n",
                "                table_name = \"carriers\",\n",
                "                sqlite_file = db_file,\n",
                "                show_progress_bar = FALSE)\n",
                "    \n",
                "    # Creating the plane data table\n",
                "    inborutils::csv_to_sqlite(\n",
                "                csv_file = py$path_plane_data,\n",
                "                table_name = \"planes\",\n",
                "                sqlite_file = db_file,\n",
                "                show_progress_bar = FALSE)\n",
                "    \n",
                "    # Creating the tables for each of the years' data\n",
                "    for (csv in main_files) {\n",
                "      csv_name <- strsplit(csv, \"/|[.]\")[[1]] # Splitting the csv name by \"/\" or \".\"\n",
                "      csv_name <- csv_name[length(csv_name)-1] # Getting the second last element of the list\n",
                "      table_name <- paste(\"table\", csv_name, sep=\"_\")\n",
                "    \n",
                "      print(\"Updating table: %s\", table_name)\n",
                "      inborutils::csv_to_sqlite(\n",
                "                  csv_file = csv,\n",
                "                  sqlite_file = db_file, \n",
                "                  table_name = table_name, \n",
                "                  pre_process_size = 1000,\n",
                "                  chunk_size = 50000, \n",
                "                  show_progress_bar = TRUE)\n",
                "    }\n",
                "    \n",
                "  }\n",
                "}\n",
                "\n",
                "save_in_sql()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now I inspect the database file to be sure that all tables have been added and updated properly\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "airline_db <- dbConnect(SQLite(), db_file) # Making a connection to db\n",
                "\n",
                "db_tables <- dbListTables(airline_db) # List out the tables in the db\n",
                "print(db_tables)\n",
                "\n",
                "db_1993_cols <- dbListFields(airline_db, \"table_1993\") # Column names for specific table in db\n",
                "print(length(db_1993_cols))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Structure of the dataset\n",
                "\n",
                "We can see from the above result that there are 29 columns in the table and this is the same across all the tables (the yearly tables), they all have the same columns, but we don't know exactly how many rows are in each table.\n",
                "\n",
                "The code below is a script/query to return exactly the number of rows (observations) that are in each table. The query can take a few minutes to execute the first time.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# count_rows <- function() {\n",
                "#     Table = character() # Empty vector/list to store table names\n",
                "#     Row_Count = integer() # Empty vector/list to store row counts\n",
                "#   \n",
                "#     for (table in db_tables) {\n",
                "#         query_rows <- sprintf(\"SELECT COUNT(*) AS Rows FROM %s\", table)\n",
                "#         row_count <- dbGetQuery(airline_db, query_rows)[[1]]\n",
                "#     \n",
                "#         Table <- c(Table, table) # Appending each table name to the vector\n",
                "#         Row_Count <- c(Row_Count, row_count) # Appending each row count to the vector\n",
                "#     }\n",
                "#   \n",
                "#     df_row_count <- data.frame(Table, Row_Count)\n",
                "#     return(df_row_count)\n",
                "# }\n",
                "# table_row_count <- count_rows()\n",
                "# table_row_count\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now see the number of rows in each table, which sums up to over 120 million observations. To test the SQL connection, I load in the first 500 rows of data from a particular year (2005 dataset in this case) using SQL and the R interface\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query_test <- \"SELECT * FROM table_2005 LIMIT 500\"\n",
                "\n",
                "tbl(airline_db, sql(query_test)) # Runs the query and displays results without loading it in memory\n",
                "\n",
                "top_rows <- dbGetQuery(airline_db, query_test) # Runs the query and stores it in a dataframe, in memory♂\n",
                "\n",
                "dbDisconnect(airline_db) # Disconnect from the database when done\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now lets look at some summary statistics for the data. I will read in the first 5,000 rows of the 2007 flight data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "top_2007 = pd.read_csv(main_files['2007'], nrows=5000)\n",
                "top_2007.info()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Most of the columns are numeric, some indicating arrival and departure, as well as different causes of delays. There are some binary columns such as \"Cancelled\" and \"Diverted\" which are important variables to analyze.\n",
                "\n",
                "#### Features of interest\n",
                "\n",
                "For this EDA, I am interested in exploring some of the ideas suggested on the source website which are:\n",
                "\n",
                "1.  When is the best time of day/day of week/time of year to fly to minimize delays?\n",
                "2.  Do older planes suffer more delays?\n",
                "3.  How well does weather predict plane delays?\n",
                "\n",
                "Generally, I am interested in exploring the cause of flight delays and cancellations.\n",
                "\n",
                "#### Areas To Focus On\n",
                "\n",
                "For this investigation, I will get the best insights by focusing on the \"delay\" columns. By analyzing the delays on each day of the week and each month, I believe I can get a good idea of the best times to fly. I will explore data for a single year. Then later on, I will compare the data across the other years to see if there are similar patterns across the years.\n",
                "\n",
                "## Univariate Exploration\n",
                "\n",
                "I will start by analyzing the departure delays: `DepDelay`. I will be using the 2007 dataset. Because the data is so large, I will only read in some select columns into the dataframe.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_2007 = pd.read_csv(main_files['2007'], usecols = ['Month', 'DayofMonth', 'ArrDelay', 'DepDelay'])\n",
                "df_2007.info()\n",
                "df_2007.describe()\n",
                "\n",
                "# Check for missing values\n",
                "df_2007['DepDelay'].isnull().sum()\n",
                "df_2007[df_2007.ArrDelay.notnull()]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Changing column data types to reduce memory usage\n",
                "df_2007 = df_2007.astype({'Month':'int8', 'DayofMonth':'int8', 'ArrDelay':'float32', 'DepDelay':'float32'})\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "binsize = 30\n",
                "bins = np.arange(0, df_2007['DepDelay'].max()+binsize, binsize)\n",
                "\n",
                "plt.figure(figsize=[14, 8])\n",
                "plt.hist(data = df_2007, x = 'DepDelay', bins = bins)\n",
                "plt.xlabel('Departure Delays (mins)')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The distribution is skewed to the left and there is a short tail. A large majority of the data falls within the range of 0 and 250 minutes. I would have gone for a logarithmic scale but this data has negative values (because there are flights that took off before the expected departure time). There are also some missing values.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Flights that took off over 25 minutes earlier\n",
                "df_2007[df_2007.DepDelay < -25].info()\n",
                "\n",
                "# Lowest departure delay\n",
                "df_2007[df_2007.DepDelay < 0].DepDelay.min()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can see that there are many flights that took off before the expected departure time (almost 50% of all the flights in that year). That is not unusual, especially if it falls within a few minutes and all passengers are available, but there are many flights that took off unusually early (over 30 minutes early, even up to 5 hours early). There can be many reasons for this but for now since this exploration is mainly focused on delay times and there are so many records to work with, I will only assess flights that were actually delayed,\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_2007_delayed = df_2007[df_2007.DepDelay > 0]\n",
                "df_2007_delayed.info()\n",
                "df_2007_delayed.describe()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now I will try to plot using a log scale\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "log_binsize = 0.025\n",
                "bins = 10 ** np.arange(0, np.log10(df_2007_delayed['ArrDelay'].max())+log_binsize, log_binsize)\n",
                "\n",
                "plt.figure(figsize=[14, 8])\n",
                "plt.hist(data = df_2007_delayed, x = 'ArrDelay', bins = bins)\n",
                "plt.xscale('log')\n",
                "# plt.xticks([500, 1e3, 2e3, 5e3, 1e4, 2e4], [500, '1k', '2k', '5k', '10k', '20k'])\n",
                "plt.xlabel('Arrival Delays (mins)')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bivariate Exploration\n",
                "\n",
                "I will look at the relationship between departure delays and arrival delays. Ideally I would expect this to be positive linear correlation very close to an 'r' value of 1 since a flight that leaves late is expected to arrive late. I know there are exceptions to this, like when there is a fault midair, unexpected weather, or when a flight gets diverted, but I expect these to be relatively few and not affect the positive correlation significantly.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dropping rows with missing values\n",
                "print(\"Original rows and columns =\",df_2007.shape)\n",
                "df_2007_sampled = df_2007.dropna(subset=['DepDelay', 'ArrDelay']).sample(n=1000, replace = False)\n",
                "print(\"Sampled rows and columns =\",df_2007_sampled.shape)\n",
                "\n",
                "print(df_2007_sampled.info())\n",
                "print(df_2007_sampled.head())\n",
                "\n",
                "plt.figure(figsize=[12, 12])\n",
                "plt.scatter(data=df_2007_sampled, x='DepDelay', y='ArrDelay')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Since there are a lot of overlapping points, I will apply some transparency to get a better picture.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=[12, 12])\n",
                "sns.regplot(data=df_2007_sampled, x='DepDelay', y='ArrDelay', scatter_kws = {'alpha': 1/5}, fit_reg = False);\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Most of the data falls within the range of 200 so I will zoom in on that group.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_2007_sampled = df_2007_sampled.query(\"DepDelay < 200\")\n",
                "\n",
                "plt.figure(figsize=[12, 12])\n",
                "sns.regplot(data=df_2007_sampled, x='DepDelay', y='ArrDelay', scatter_kws = {'alpha': 1/5}, fit_reg = False);\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is in line with my predictions so I will go ahead and analyze other variables, since I am sure that the delay times are consistent.\n",
                "\n",
                "#### Day of Week Analysis\n",
                "\n",
                "Next, I will analyze the delays on a `day-of-week` basis.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_mean_delay_year <- function(year) {\n",
                "    airline_db <- dbConnect(SQLite(), db_file) # Making a connection to db\n",
                "    \n",
                "    # Query for mean delay times in January (actual delays, no early flights)\n",
                "    query_jan <- sprintf(\"SELECT DayOfWeek, DayOfMonth, \n",
                "                                 AVG(DepDelay) AS MeanDepDelay, \n",
                "                                 AVG(ArrDelay) AS MeanArrDelay\n",
                "                          FROM table_%s\n",
                "                          WHERE DepDelay > 0 AND ArrDelay > 0\n",
                "                          GROUP BY DayOfWeek, DayOfMonth\", year)\n",
                "    \n",
                "    # tbl(airline_db, sql(query_jan)) # Runs the query and displays results without loading it in memory\n",
                "    delays_2007 <- dbGetQuery(airline_db, query_jan) # Runs the query and stores it in a dataframe, in memory♂\n",
                "    dbDisconnect(airline_db) # Disconnect from the database when done\n",
                "    return(delays_2007)\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "delays_2007 <- get_mean_delay_year('2007')\n",
                "str(delays_2007)\n",
                "skim(delays_2007)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For the `DayOfWeek` data, I will make another column in the dataframe that shows the text representation (Monday, Tuesday ...) so that it would be easier to understand in the plot.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def change_column_type(df):\n",
                "    # Converting R dataframe to Pandas dataframe\n",
                "    df_delays = pd.DataFrame(df)\n",
                "    \n",
                "    # Changing day and month columns from float to integer data types\n",
                "    df_delays = df_delays.astype({'DayOfWeek':'int8', 'DayofMonth':'int8'})\n",
                "    \n",
                "    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
                "    \n",
                "    # Creating the new column\n",
                "    df_delays['Day'] = df_delays['DayOfWeek'].apply(lambda x: days_of_week[x-1])\n",
                "    \n",
                "    return(df_delays)\n",
                "\n",
                "delays_2007 = change_column_type(r.delays_2007)\n",
                "delays_2007.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=[16,12])\n",
                "sns.barplot(data=delays_2007, x='Day', y='MeanDepDelay')\n",
                "plt.title(\"Average Flight Delay Times In 2007\")\n",
                "plt.xlabel(\"Day of Week\")\n",
                "plt.ylabel(\"Average Departure Delay (min)\")\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the above chart alone, we can see that there is a wider range of delay (in minutes) on Sundays, followed by Wednesdays and Tuesdays. Also, there is at least one flight on a Sunday that was delayed for over 55 minutes. The days with the least median (50th percentile) delay times are Tuesday and Saturday (around 35 minutes). I will see if there is a consistent theme across the years by plotting the chart for 9 consecutive years (1999 - 2008)\n",
                "\n",
                "**I left the colors because, even though the weekday variable is ordinal (i.e. Tuesday comes after Monday and so on), the order doesn't really matter much in this case because, for example, Friday is not better than Sunday, Monday is not higher than Saturday, etc. The colors will be helpful in identifying each weekday in the subsequent plots.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "delays_2000 <- get_mean_delay_year('2000')\n",
                "delays_2001 <- get_mean_delay_year('2001')\n",
                "delays_2002 <- get_mean_delay_year('2002')\n",
                "delays_2003 <- get_mean_delay_year('2003')\n",
                "delays_2004 <- get_mean_delay_year('2004')\n",
                "delays_2005 <- get_mean_delay_year('2005')\n",
                "delays_2006 <- get_mean_delay_year('2006')\n",
                "delays_2007 <- get_mean_delay_year('2007')\n",
                "delays_2008 <- get_mean_delay_year('2008')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "delays_2000 = change_column_type(r.delays_2000)\n",
                "delays_2001 = change_column_type(r.delays_2001)\n",
                "delays_2002 = change_column_type(r.delays_2002)\n",
                "delays_2003 = change_column_type(r.delays_2003)\n",
                "delays_2004 = change_column_type(r.delays_2004)\n",
                "delays_2005 = change_column_type(r.delays_2005)\n",
                "delays_2006 = change_column_type(r.delays_2006)\n",
                "delays_2007 = change_column_type(r.delays_2007)\n",
                "delays_2008 = change_column_type(r.delays_2008)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(ncols = 3, nrows = 3 , figsize = [17,17])\n",
                "\n",
                "sns.barplot(data=delays_2000, x='Day', y='MeanDepDelay', ax = ax[0, 0])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2001, x='Day', y='MeanDepDelay', ax = ax[1, 0])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2002, x='Day', y='MeanDepDelay', ax = ax[2, 0])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2003, x='Day', y='MeanDepDelay', ax = ax[0, 1])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2004, x='Day', y='MeanDepDelay', ax = ax[1, 1])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2005, x='Day', y='MeanDepDelay', ax = ax[2, 1])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2006, x='Day', y='MeanDepDelay', ax = ax[0, 2])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2007, x='Day', y='MeanDepDelay', ax = ax[1, 2])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "sns.barplot(data=delays_2008, x='Day', y='MeanDepDelay', ax = ax[2, 2])\n",
                "# plt.title(f\"Average Flight Delay Times In {delay_tables}\")\n",
                "\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From a high level overview of the chart above, there is no consistent trend to predict which weekdays have more delays. This is expected because there are many other factors to consider like the month, the season, holidays, airport carrier, plane age and global events.\n",
                "\n",
                "#### Cancelled and Divertd\n",
                "\n",
                "Now I will examine the cancelled and diverted flights, specifically the unique carriers. I want to see if flights from a carrier tend to get get cancelled or diverted more than others. \n",
                "\n",
                "Below is an SQL query to get all flights that were either diverted or cancelled and group them by the flight carrier. On the original table, there is a column for diverted (1 or 0) and another column for cancelled (1 or 0). I believe the data is not completely tidy because a flight that is cancelled cannot be diverted and vice-versa. So I combined them to a single column indicating whether the flight was cancelled or diverted.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "airline_db <- dbConnect(SQLite(), db_file) # Making a connection to db\n",
                "\n",
                "get_changed_flights <- function(year) {\n",
                "    \n",
                "    query <- sprintf(\"SELECT \n",
                "                        UniqueCarrier,\n",
                "                        Description AS Carrier,\n",
                "                        CASE \n",
                "                            WHEN Diverted = 1 AND Cancelled = 0 THEN 'Diverted'\n",
                "                            WHEN Diverted = 0 AND Cancelled = 1 THEN 'Cancelled'\n",
                "                        END AS FlightChange,\n",
                "                        COUNT(*) AS Flights\n",
                "                      FROM table_%s\n",
                "                      LEFT JOIN carriers\n",
                "                      ON table_%s.UniqueCarrier = carriers.Code\n",
                "                      WHERE Diverted = 1 OR Cancelled = 1\n",
                "                      GROUP BY UniqueCarrier, FlightChange\n",
                "                      ORDER BY UniqueCarrier\", year)\n",
                "    \n",
                "    flights_changed <- dbGetQuery(airline_db, query) # Runs the query and stores it in a dataframe, in memory♂\n",
                "    dbDisconnect(airline_db) # Disconnect from the database when done\n",
                "    return(flights_changed)\n",
                "}\n",
                "\n",
                "flights_changed_2007 = get_changed_flights('2007')\n",
                "flights_changed_2007\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "There are 138,120 records of cancelled or diverted flights in 2006. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "flights_changed_2007 = pd.DataFrame(r.flights_changed_2007)\n",
                "\n",
                "flights_changed_2007.head()\n",
                "print(f\"Total number of diverted or cancelled flights in 2007: {flights_changed_2007.Flights.sum()}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=[16,12])\n",
                "sns.barplot(data = flights_changed_2007, x = 'UniqueCarrier', y = 'Flights', hue = 'FlightChange')\n",
                "plt.title(\"Cancelled & Diverted Flights From Each Carrier In 2007\")\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can already see that `MQ` had the highest number of cancelled flights (by a relatively wide margin). To better understand the plot, I will make it horizontal and order it by number of cancelled flights.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "flights_changed_2007 = flights_changed_2007.sort_values(by='Flights', ascending=False)\n",
                "plt.figure(figsize=[16,12])\n",
                "sns.barplot(data = flights_changed_2007, y = 'Carrier', x = 'Flights', hue = 'FlightChange')\n",
                "plt.title(\"Cancelled & Diverted Flights From Each Carrier In 2007\")\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I believe its easier to see that the airline companies with the most number of `cancelled` flight is **E** and `diverted` flights are **A B C**. So we can at least infer that the carriers at the bottom of the chart have a good record of flight data. \n",
                "\n",
                "Now I'm going to plot the chart for the most recent 6 years from the dataset, to see if this trend is the same across the years, `i.e, to see if the same companies are always on top.`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above is a plot of average delay times for each day of the week of all the flights in 2007 (the 2007 table). Just judging by this plot alone, we can see that the longest delays occurred on Wednesdays, followed by Thursdays and Fridays. The days with the shortest delays are Mondays and Tuesdays. We can also see a the highest bulge in on Saturdays indicating the highest frequency of delays\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
